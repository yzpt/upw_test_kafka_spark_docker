version: "3.8"
services:
# === kafka ===========================================================
  zookeeper:
    container_name: zookeeper
    image: wurstmeister/zookeeper
    ports:
      - "2181:2181"
    networks:
      - cluster

  kafka:
    container_name: kafka
    image: wurstmeister/kafka
    ports:
      - "9092:9092"
      - "1099:1099"
    environment:
      KAFKA_LISTENERS: SASL_PLAINTEXT://:9092
      KAFKA_ADVERTISED_LISTENERS: SASL_PLAINTEXT://localhost:9092
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_OPTS: "-Djava.security.auth.login.config=/etc/kafka/kafka_broker_jaas.conf"
      KAFKA_INTER_BROKER_LISTENER_NAME: SASL_PLAINTEXT
      KAFKA_SASL_ENABLED_MECHANISMS: PLAIN
      KAFKA_SASL_MECHANISM_INTER_BROKER_PROTOCOL: PLAIN
      KAFKA_AUTHORIZER_CLASS_NAME: kafka.security.authorizer.AclAuthorizer
      KAFKA_SUPER_USERS: "User:admin"
      KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: "true"
      KAFKA_JMX_OPTS: "-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.rmi.server.hostname=127.0.0.1 -Dcom.sun.management.jmxremote.rmi.port=1099"
      # JMX_PORT: 1099
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./kafka_broker_jaas.conf:/etc/kafka/kafka_broker_jaas.conf
      - ./alice-client.properties:/etc/kafka/alice-client.properties
      - ./admin-client.properties:/etc/kafka/admin-client.properties
      - ./madhu-client.properties:/etc/kafka/madhu-client.properties
    networks:
      - cluster


# === Spark =======
  spark-master:
    image: bitnami/spark:3.4.1
    container_name: spark-master
    ports:
      - "9090:8080"
      - "7077:7077"
    volumes:
      - ./spark_entrypoint.sh:/entrypoint.sh
      - ./spark_streaming.py:/opt/bitnami/pyspark_scripts/spark_streaming.py
      - ./vol_spark_checkpoint:/opt/bitnami/pyspark_scripts/checkpoint
      - ./kafka_broker_jaas.conf:/opt/bitnami/spark/conf/kafka_broker_jaas.conf
    command: ["/bin/bash", "/entrypoint.sh"]
    networks:
      - cluster
  
  spark-worker:
    image: bitnami/spark:3.4.1
    container_name: spark-worker
    command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    depends_on:
      - spark-master
    environment:
      SPARK_MODE: worker
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 1g
      SPARK_MASTER_URL: spark://spark-master:7077
    networks:
      - cluster



# === Cassandra ====================================================================================================
  cassandra:
    image: cassandra:5.0
    container_name: cassandra
    hostname: cassandra
    volumes:
      - ./vol_cassandra_data:/var/lib/cassandra
    ports:
      - 9042:9042
    environment:
      - MAX_HEAP_SIZE=512M
      - HEAP_NEWSIZE=100M
      - CASSANDRA_USERNAME=cassandra
      - CASSANDRA_PASSWORD=cassandra
    networks:
      - cluster

networks:
  cluster:
    